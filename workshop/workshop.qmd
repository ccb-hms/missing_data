---
title: "Missing data workshop"
author: 
  - name: Andrew Ghazi
    email: Andrew_Ghazi@hms.harvard.edu
    affiliation:
      - name: CCB
        url: https://ccb.hms.harvard.edu/ 
format: 
    html:
        code-fold: show 
        toc: true
        toc-depth: 2
        code-tools: true
        theme: 
          light: a11y
          dark: darkly
---


<!-- Repo: https://github.com/ccb-hms/missing_data/tree/main/workshop -->
<!-- Rendered output here: https://ccb.connect.hms.harvard.edu/missing_data_workshop/ -->

# Setup

First load some libraries and set some options:

```{r}
#| message: false

library(dplyr)
library(purrr)
library(ggplot2)
library(mice)
library(ggmice)
library(brms)

ncores <- ifelse(interactive(), 4, 1)

options(digits = 3)
```

```{r}
#| eval: true
#| echo: false

# Some tweaks to save time when I'm re-rendering this locally:

fw = Sys.info()['user'] == "ghazi"

if (fw) {
  ncores = 4
  options(brms.backend = "cmdstanr")
  out_dir = "~/projects/missing_data/fits/"
}
```

:::{.callout-note title="Data cleaning" collapse="true"}
This workshop does not cover the data munging/cleaning steps that are often necessary to convert empty strings `""` or human readable values like `"Not applicable"` to proper `NA` values. To learn more about that topic, we suggest [R for Data Science](https://r4ds.hadley.nz/missing-values.html).
:::

# Exploring data with missingness

This section is adapted from the main `ggmice` vignette located [here](https://amices.org/ggmice/articles/ggmice.html#the-ggmice-function). The package has more functionality than we'll have time to cover, so we'll just look at the main highlights.

The data we'll use are growth records of 748 Dutch boys from 1997, see `?boys`. We'll take a subset of variables of interest:

```{r}
boys <- boys |> select(age:bmi, reg)

dim(boys)

head(boys)
```

Define a function to count the number of NAs in a vector and apply it to each column: 

```{r}
count_na <- function(x) x |> is.na() |> sum()

map_int(boys, count_na)
```

## Visualizing NAs

Replace `ggplot()` in an otherwise standard ggplot2 command with `ggmice()` and you'll get a comparable version that highlights NAs on their respective axes: 

```{r}
ggmice(boys, aes(age, hgt)) + 
  geom_point()
```

:::{.callout-tip title="Themes and axes" collapse=true}
`ggmice` respects ggplot themes, so you can add `+ theme_minimal()` to avoid showing points underneath the x-axis. We've left it at the default for simplicity.

```{r}
#| code-fold: false
ggmice(boys, aes(age, hgt)) + 
  geom_point() +
  theme_minimal()
```

:::

You can see that most of the boys whose heights weren't observed are on the younger side. You can also notice from this that there are no observations whose ages are NA.

`ggmice` also respects facets. Let's classify the regions into city and suburbs and plot those as facets:

```{r}
boys |> 
  mutate(region = case_when(reg == "city" ~ "city",
                            reg != "city" ~ "suburbs")) |> 
  ggmice(aes(age, hgt)) + 
  geom_point() + 
  facet_wrap(vars(region))
```

You can see there are three observations with observed height and age, but no region specified.

There's a handy convenience function `plot_pattern()` that shows which combined missingness patterns are observed:

```{r}
plot_pattern(boys)
```

It looks complicated at first, but stare at it and it's pretty intuitive:

* The columns are variables in your data frame (reordered)
* Rows are specific missingness patterns
* The left side gives how many times that pattern occurred
* The bottom shows the total number missing in a given variable
* The right shows the number of variables missing in a given pattern

## Visualizing imputed datasets 

In addition to visualizing the missingness in data, `ggmice` also has functionality to help visualize imputed values. This is important in practice because reasonable imputation models are essential for accurate downstream inference.

First use `mice` to generate three imputed datasets:  

```{r}
imp <- mice(boys, 
            m = 3, 
            print = FALSE)
```

Our result `imp` is a so-called `mids` object that contains our multiply imputed data set. Three is usually not enough, use more when analyzing real data.

When provided with an multiply imputed dataset like `imp`, `ggmice` displays the imputed values in red:

```{r}
ggmice(imp, aes(age, hgt)) + 
    geom_point()
```

A couple things to notice here:

* There are three red points for each age with an imputed value - that's because we specified `m = 3` imputations above.
* The default imputation model didn't yield amazing imputations for the younger boys with missing height. There are many imputed values far below the main trend.

:::{.callout-tip title="Changing imputation method" collapse="true"}
You can change the imputation method by specifying the `method` argument with a vector naming the imputation method for each column. The method needs to be appropriate for the type of the variable (i.e. numeric, binary, ordered, etc) or `""` for complete variables that don't need imputation. 

In this particular example we could replace the default predictive mean matching for numeric variables with Bayesian linear regression by setting `method = c("", rep("norm", 3), "polyreg")`. That basically says "don't impute age, use Bayesian linear regression for height, weight, and bmi, and use polytomous logistic regression for region.

See `?mice::mice` for a complete list of available methods and `?mice::mice.impute.*` for specific options. It's also possible to write your own custom `mice.impute.custom()` function if you want to use a predictive ML model to generate imputed values.
:::

```{r}
#| eval: false
#| echo: false

imp <- mice(boys, 
            m = 3,
            method = c("", rep("norm", 3), "polyreg"))
```

You can also plot variables by imputation number by handing the special variable `.imp` to `ggmice`:

```{r}
ggmice(imp, aes(.imp, hgt)) + 
    geom_boxplot(outlier.shape = NA) + 
    geom_jitter(height = 0, width = .3)
```

If you notice that there is substantial variability in between-imputation distributions, you'll need to increase the number of imputations to integrate over that.


# Multiple imputation in `mice` - example with ignorability

Now let's try a missing data analysis of the `boys` dataset with `mice`. The general workflow is

* multiply impute with `mice()`
* run analysis models with `with()`
* and pool with `pool()`

Let's assume our field of study is obesity and we're interested to understand the relationship of our covariates and weight.

:::{.callout-caution title="Think about the variables to include" collapse="true"}

We've assumed we're obesity researchers. Let's say that we want to study weight as the outcome variable. It makes sense to include:

* age - children get heavier as they get older
* height - taller children are heavier on average
* region - probably not as impactful as age and height, but we can allow the possibility that some regions have different food cultures or something

Does it make sense to include BMI? No! BMI is a direct function of height and weight (`BMI = weight_kg / height_m^2)`), so giving the imputation model access to both BMI and height will allow it to generate unrealistically accurate imputed weights. That's particularly true if we allow for non-linear imputation models that can back-out the w/h^2 relationship.
:::

## Generate multiple imputations

This is simply done with the `mice()` function. Let's try the default imputation method again. Set the RNG seed and drop BMI:


```{r}
set.seed(42)

(imp <- mice(boys |> select(-bmi), 
             print = FALSE))
```

The result `imp` is a `mids` object, meaning a "multiply imputed dataset".

## Visualize imputed values

Let's look at the imputed age/height values:

```{r}
ggmice(imp, aes(age, hgt)) + 
  geom_point()
```

Now that we've dropped BMI, the default imputation model for height (predictive mean matching `pmm`) works better -- the imputations look more realistic. It's perhaps underselling the variance for a couple older boys, but set `m = 100` and you'll see that this is mostly due to getting unlucky from the seed used. It particularly looks better for the younger boys who were imputed as too short before.

:::{.callout-info title="Exercise: Try other imputation methods" collapse=true}

Try some other imputation methods like Bayesian linear regression, LASSO, CART, and random forest imputation. Do any work well out of the box? Hint: they can, with some additional tweaks to the predictor matrix. 

:::

Let's check the distribution of imputed heights too:

```{r}
ggmice(imp, aes(.imp, hgt)) + 
  geom_boxplot()
```

Looks fine. Remember most of the imputed values are from younger kids, so it's fine that they don't match the overall distribution. In practice you'd want to sanity check the other imputed variables as well, but let's move on.

## Fit models to imputed datasets

Now we fit the model of interest to each of our imputed datasets. For the sake of simplicity let's say we want to estimate weight `wgt` from `age`, height `hgt`, and region `reg` with a linear model i.e. `wgt ~ age + hgt + reg`. To do this we put the model fitting function we would normally use (`lm()`) inside the function `with()` with no data argument: 

```{r}
fit <- with(imp, lm(wgt ~ age + hgt + reg))
```

## Pool results

:::{.callout-info title="Multiply imputed repeated analyses statistics"}
TODO define these more clearly

* mean estimate
* ubar ~= mean of the variances
* `b` - between-imputation variance
* Relative increase in variance `riv`
* Proportion of total variance due to missingness `lambda`
* Fraction of missing information `fmi`

:::

Then finally we can aggregate the multiple fits with the `pool()` function:

```{r}
pool(fit)
```

This gives a pooled outcome object. It shows some of the different variances related to the missingness/imputation, but if you want a summary of the estimates you need to pass it through `summary()`:

```{r}
pool(fit) |> summary()
```


:::{.callout-note collapse="true" title="Assessing the impact of missing data analysis"}

The impact of missing data analysis depends on the dataset, missingness patterns/proportion, and the statistical model. You can see that just dropping NAs actually yields very similar coefficient estimates in this case:

```{r}
boys |> 
  na.omit() |> 
  lm(wgt ~ age + hgt + reg,
     data = _) |> 
  coef()
```

Obtaining similar estimates from the complete cases makes sense: we have over 700 complete cases and relatively few observations with NAs. The information gain from a handful of incomplete cases is negligible in this instance. There's also no indication that there is some insidious biasing from patterned missingness. 

But of course, it's context dependent. Unlike this toy dataset, in real world datasets there are sometimes zero complete cases. In practice, analysts have to use simulations and exploratory data analysis to check whether missing data analysis might be advantageous.
:::

# Imputing single-cell expression

In single-cell experiments, barcodes are known to "drop out". That means that a barcode just stochastically fails when profiling a given cell. There's a developing literature on understanding this process and what to do about it:

* [Demystifying “drop-outs” in single-cell UMI data](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02096-y)
* [Zero-preserving imputation of single-cell RNA-seq data](https://www.nature.com/articles/s41467-021-27729-z)

In this section we'll look at a synthetic example to see how well imputation can "rescue" some dropped out expression values. For the sake of brevity, rather than doing differential expression or some complicated analysis, we'll just examine the original, dropped-out, and imputed datasets with UMAPs to see how they compare.

In practice, dropouts in single-cell data manifest themselves as aberrant zeros. A cell that has extremely high expression of neuron genes A, B, and C is probably a neuron. If it has a zero for neuron gene D, that zero is probably a dropout based on the context from A, B, and C. 

Deciding which zeros are biological versus technical dropouts is a difficult statistical problem that we are going to ignore in this workshop. For the sake of simplicity, we'll assume that we've used some upstream tool that has accurately labelled "suspicious" zeros and replaced them with NAs.

:::{.callout-warning title="Oversimplification alert!"}
The process demonstrated in this section is simplified and unrealistic for demonstrative reasons. Don't try to adapt this for your own work. There's a [developing literature](https://pubmed.ncbi.nlm.nih.gov/?term=single+cell+expression+%22imputation%22+%22impute%22) around single cell expression imputation. It's an open question as to what experimental factors provide the most predictive information and the best way to incorporate them into an imputation model.
:::

## Get the data

We'll first need to download the data from GitHub. For completeness, here's the script used to generate this data with some Bioconductor packages and the Zeisel brain dataset. You don't need to run this.

```{r}
#| eval: false
#| code-fold: true

{{< include R/dropout_zeisel.R >}}
```

**NA generating process:** 

* identifies the 20 most highly expressed genes in the **pyramidal CA1** cell type in the classic Zeisel Brain Data, and 
* replaces 20% of the observations in those genes of those cells with NA (note, not that many overall). 
  * NAs are introduced completely at random (actually a fairly reasonable missingness model in the context of single cell barcode dropout)

You can download and load the data like so:

```{r}
#| eval: false
#| echo: true

url <- "https://github.com/ccb-hms/missing_data/raw/refs/heads/main/workshop/data/sc.RData"

f <- tempfile()

download.file(url, f)

load(f, verbose = TRUE)
```

```{r}
#| eval: true
#| echo: false

load("data/sc.RData")
```

It contains:

* the original data `dat`
* the same data with NAs `na_dat`
* 20 genes whose expression values have dropouts `to_imp`

The data contains a few thousand cells and 500 highly variable genes: 

```{r}
dim(dat)

names(dat) |> head(20)

dat[1:5,1:7]
```

## Original UMAP

First, let's look at a UMAP of the original data (pre-computed):

```{r}
#| code-fold: true
ggplot(dat, aes(umap_1, umap_2)) + 
  geom_point(aes(color = l1c),
             pch = 15, size = .3) + 
  labs(title = "Original data UMAP") +
  guides(color = guide_legend(override.aes = list(size = 2)))
```

Pyramidal CA1 cells are the green ones.

## UMAP with dropouts

Now let's check the same UMAP for the data that drops the NAs with `na.omit()`:

```{r sc_na_umap}
#| message: false

rlang::check_installed("uwot") # In case you don't have uwot, install it.

library(uwot)

na_umap <- na_dat |>
  select(-(cell_id:l1c)) |>
  na.omit() |>
  as.matrix() |>
  umap() |>
  as.data.frame() |>
  rename(umap_1 = V1, umap_2 = V2) |>
  mutate(l1c = na.omit(na_dat)$l1c)

ggplot(na_umap, aes(umap_1, umap_2)) + 
  geom_point(aes(color = l1c),
             pch = 15, size = .3) + 
  labs(title = "Dropout UMAP") + 
  guides(color = guide_legend(override.aes = list(size = 2)))
```

You can see the shape of most of the blobs has stayed the same, but the pyramidal CA1 cells have mostly been removed.

## Imputed UMAP

Now let's run a single imputation. There are better ways to do this, but let's just use `mice`. **This will take a minute** since there are 20 genes with missing values and so many predictors for each one.

```{r scmice}
#| eval: false

imp_input <- na_dat |>
  as.data.frame() |>
  select(-(cell_id:l1c))

rownames(imp_input) <- na_dat$cell_id

imp <- mice(m = 1,
            imp_input, 
            method = "norm",
            print = FALSE)

```

```{r}
#| eval: true
#| echo: false

# save local rendering time

if (fw) {
  load("data/imp_precompute.RData")
} else {
  imp_input = na_dat |> 
    as.data.frame() |> 
    select(-(cell_id:l1c))
  
  rownames(imp_input) = na_dat$cell_id
  
  imp = mice(m = 1,
             imp_input, 
             method = "norm",
             print = FALSE)
  
}
```

:::{.callout-tip title="`futuremice`" collapse=true}
Out in the real world, big, complicated problems can require large numbers of imputations for stable inference. If running multiple imputations starts to take a long time, you can use the function `futuremice()` to run the imputations in parallel. 
:::

Note that the imputation here ignores the cell type labels. A more rigorous implementation would probably want to work in that information. Exercise for the reader.

Now we need to plug the imputed values back into the data frame on top of their respective NAs. `mice` generally discourages extracting the inner components of a `mids` object, but just this once:

```{r}
imp_dat <- imp_input

# Copy the imputed values into their respective places in imp_dat:
for (g in to_imp) {
    g_imp <- imp$imp[[g]]
    
    imp_dat[[g]][match(rownames(g_imp), rownames(imp_dat))] <- g_imp$`1`
}
```

And now let's compute and plot a UMAP of the imputed expression values:

```{r impumap}
imp_umap <- imp_dat |> 
    as.matrix() |> 
    uwot::umap() |> 
    as.data.frame() |> 
    rename(umap_1 = V1, umap_2 = V2) |> 
    mutate(na_dat |> select(l1c)) 

imp_umap |> 
  ggplot(aes(umap_1, umap_2)) + 
  geom_point(aes(color = l1c),
             pch = 15, size = .3) + 
  labs(title = "UMAP with imputed values") + 
  guides(color = guide_legend(override.aes = list(size = 2)))

```

Pretty good! This is not a rigorous comparison of the imputed against original values, but it seems to have recovered that green blob and its relative position/shape pretty well.

:::{.callout-note title="Exercise"}

Try comparing the imputed values for Plp1 against the true values. Are they any good? Solution in the source code.

```{r}
#| echo: false
#| eval: false

imp_vals <- imp_dat$Plp1[match(rownames(g_imp), rownames(imp_dat))]

tru_vals <- dat$Plp1[match(rownames(g_imp), dat$cell_id)]

plot(tru_vals, imp_vals)

abline(0,1)

# Pretty good correlation for most of the cells with non-zero expression, though
# you can tell that our imputation model didn't understand that the expression
# values were strictly greater than 0. Another thing to try might be running the
# imputation on the log expression values.
```

:::

# Joint imputation in `brms` 

`mice` covers the common and important simple cases, but it can't cover everything. Non-ignorable missingness patterns or complicated joint models necessitate bespoke probability models.

The intuition is the same: integrate over the uncertainty from the missing values. The key differences are:

1. imputed values are treated the same as other unknown model parameters (e.g. regression coefficients)
1. the pooling is treated as any other posterior summary
1. the probabilistic relationships of known and imputed values is whatever you specify -- it's not limited to imputed = f(known)

`brms` is an R package that allows fitting probability models with [Stan](https://mc-stan.org/). We won't be getting into the weeds of inference with Stan, but it's useful in the context of missing data because it enables accurate inference of the complicated models at hand. 

We'll use a tiny set of 25 observations in the `nhanes` dataset which includes age, BMI, and cholesterol measurements:

```{r}
head(nhanes)
```

Here we fit a joint model on the `nhanes` data that simultaneously:

1. imputes missing values in cholesterol as a function of age with `mi()`
1. models BMI as an interaction of age and imputed cholesterol

We first specify a model formula with two components for the two submodels. We also specify that the residuals are uncorrelated:

```{r m1}
#| message: false
#| warning: false

bform <- bf(chl | mi() ~ age) + 
  bf(bmi | mi() ~ age * mi(chl)) +
  set_rescor(FALSE)  # don't model residual correlation of submodels

out_dir <- tempdir()
```

Then we hand that to the main fitting function `brm()` with the data and some QOL options:

```{r}
#| echo: false
if (fw) {
  
  out_dir = "~/projects/missing_data/fits/"
}
```


```{r fitm1}
#| message: false
#| warning: false
(fit_imp <- brm(bform,
                data = nhanes, 
                cores = ncores, 
                refresh = 0,
                silent = 2,
                seed = 123,
                file = file.path(out_dir, "fit_imp")))
```

This demonstrative example doesn't yield any shocking results, but the implementation demonstrates the flexibility. You can have multiple interacting submodels, imputed values that depend on other imputed values, non-linear link functions, etc.

At the end you have a single set of posterior draws from the entire joint model. The posterior draws include both model coefficients and imputed values because both are parameters from the model's point of view. Computing averages and quantiles over these draws is how you numerically integrate over the uncertainty. Inspecting, visualizing, and assessing the draws and summaries are relatively simple using [existing ecosystem](https://mc-stan.org/tools/) around `brms`.

In the event that you have data that is NMAR yet "rescuable" through informative auxiliary variables, this is a good place to start.

# Links

* [Flexible Imputation of Missing Data](https://stefvanbuuren.name/fimd/)
* [Handle Missing Values with brms](https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html)
* [CCB Computational Resources](https://ccb.connect.hms.harvard.edu/comp_resources/ccb_resources.html)
* [CCB Office Hours](https://dbmi.hms.harvard.edu/about-dbmi/core-computational-biomedicine/office-hours)
* [Statistical Rethinking by Richard McElreath](https://xcelab.net/rm/statistical-rethinking/)
  * [Lecture series on YT (esp. 1-13)](https://www.youtube.com/playlist?list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus)
  * [brms + tidyverse translation of official text](https://bookdown.org/content/4857/)
* [R for Data Science](https://r4ds.hadley.nz/)



Related packages we didn't have time that may be of interest:

* [VIM](https://cran.r-project.org/web/packages/VIM/index.html)
* [naniar](https://cran.r-project.org/web/packages/naniar/index.html)


