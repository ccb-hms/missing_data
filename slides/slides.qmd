---
title: "Working with NAs and Missing Data"
author: "Andrew Ghazi"
institute: "Core for Computational Biomedicine"
date: last-modified
format: 
    revealjs:
      theme: [default, my_theme.scss]
      width: 1600
      height: 900
      incremental: false 
      transition: fade
      background-transition: fade
      transition-speed: fast
      chalkboard: true
      slide-number: c/t
      controls: true
      controls-layout: edges
      controls-tutorial: true
        
title-slide-attributes:
  data-background-image: images/HMS_DBMI_Logo.png
  data-background-size: 25%
  data-background-position: 10% 10%
---

<!-- Repo: https://github.com/ccb-hms/missing_data/tree/main/slides -->
<!-- Rendered output: https://ccb.connect.hms.harvard.edu/missing_data -->

# Preface

```{r setup}
#| message: false
library(fastverse)
library(tinyplot)
# library(ggplot2)
library(ggbeeswarm)
set.seed(123)

ow = "#F2F2F2"

ow_rect = element_rect(fill  = ow, 
                       color = ow)

ow_bg = theme(panel.background = ow_rect,
              plot.background  = ow_rect)
```

## Who we are

> The Core for Computational Biomedicine (CCB) is a multi-disciplinary team of computational and quantitative scientists that collaborates with HMS Quad-based researchers to develop tools, platforms, and other data science and computational solutions that broadly enable biomedical discovery and innovation.

* Collaborative projects
* Office hours
* Workshops

:::{#headshots layout-ncol=1 style="text-align: center"}

![Andrew Ghazi, PhD](images/Andrew_Ghazi_003_sq_sm2.JPG){height=220}

<!-- + other CCB folks -->
:::

## CCB R/Stats Office Hours

::::{.columns}

:::{.column width="55%"}
* Quick help on R/Stats and CompBio
* Book Zoom any day or in-person on Wednesdays
* Examples:
  * Data wrangling / plotting messy health database exports
  * Prognostic modeling of surgery patients from imaging features with random forests
  * R project installation & organization
  * Running AlphaFold3 on O2
:::

:::{.column width="45%"}
![](images/oh.png)

<!-- Other figure elements to possibly include: -->
<!-- * survey / Kaplan Meier plot -->
<!-- * GWAS -->
<!-- * UMAP -->
:::

::::

:::{.absolute left=0 top=770}
Link in my email signature or at [https://dbmi.hms.harvard.edu/about-dbmi/core-computational-biomedicine/office-hours](https://dbmi.hms.harvard.edu/about-dbmi/core-computational-biomedicine/office-hours) 
:::

## Prerequisites:

* Seminar: none
* Hands-on workshop: R and the packages below:

```{r}
#| eval: false
#| echo: true

pkgs <- c("ggplot2", "dplyr", "purrr", 
          "mice", "ggmice", "brms")

install.packages(pkgs, Ncpus = 4)
```

## Missing data and NAs

:::{.column width=60%}
* ubiquitous and important problem
* decent methods exist
* methods aren't challenging, routine for ~15 years


:::{.fragment}
* **BUT** a thorough overview requires advanced methods 

![](images/m2.png){width=80% fig-align="center" style="filter: drop-shadow(0 0 0.75rem grey);"}
:::

:::

:::{.absolute left=970 top=40 width=50%}
```{r}

ins_na = \(x) {
  x[sample(length(x), floor(n/3))] = NA
  x
}

n = 200
set.seed(123)
ex_dat = data.table(allerg = sample(0:1, n, TRUE) |> ins_na(),
                    age = floor(runif(n, 30,80))     |> ins_na(),
                    income = floor(rexp(n, 1/48))    |> ins_na(),
                    `5y_outcome` = sample(0:1, n, T) |> ins_na())

ex_dat$income[1] = 20
ex_dat$allerg[2] = NA

ex_dat[1:5,-1] |> 
  print(row.names = FALSE)
```
:::

[<span style="color:#666666; font-style: italic;"> <small> Missing values in survey data </small> </span>]{.absolute left=1000 top=390}

![ ](images/dg_tmp.png){.absolute left=1000 top=460 width=40%} 

[<span style="color:#666666; font-style: italic;"> <small> Missing values in imaging data </small> </span>]{.absolute left=1000 top=870}

## Outline 

:::{.column width=70%}
* Seminar (1 hour)
  * Concepts
  * Strategies
  * Examples
  * No theory!
* Hands-on workshop  in R (1 hour)

These slides:

[ccb.connect.hms.harvard.edu/missing_data](ccb.connect.hms.harvard.edu/missing_data)

:::

![](images/2025-06-11_15-35-18.png){fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);" .absolute left=1000 top=50 width=33%}
![](images/no.svg){fig-alt="" .absolute left=985 top=20 .fragment width=35%}

# Concepts 

## Degrees of uncertainty

* Fill in the blank: 
    * "Harvard Uni_ersity"
    * "_ight" 

:::{.fragment}
* "Imputation" - the act of filling in blanks
:::

:::{.incremental}

1. high or low uncertainty over missing values
1. degree of uncertainty impacted by context
:::

## Degrees of uncertainty 

::::{.columns}

:::{.column width=50%}
* Context informs uncertainty when imputing
* If the uncertainty is *sufficiently* small, it can be ignored
* What will you use imputed values for?
    * Just reporting / visualizing? Uncertainty is less important.
    * As input to a downstream model? Accounting for uncertainty is **essential**.
:::

:::{.notes}
* People generally ascribe negative value to uncertainty
:::

:::{.column width=50%}
```{r}

set.seed(42)

n = 30
s = .06
d = data.frame(x = rnorm(n)) |> 
    mtt(y = rnorm(n, 1*x, sd = s),
        z = rnorm(n, 1*x, sd = 1))

tinytheme("clean2", 
    mar = c(4.5,4,1,1),
    bg = ow,
    cex.axis = 1.5)

par(mfrow = c(1,2))

plt(d$x, d$y, 
     xlab = "", 
     ylab = "", 
     ylim = range(c(d$y, d$z)), 
     pch = 19)

tinyplot(col = "firebrick2",
         add = TRUE,
         type = "lines",
      c(1,1),
      c(1+s*2, 1-s*2),
      lwd = 2)

# points(1, 1, col = "firebrick2", pch = 21, cex = 1.3)

plt(d$x, d$z, 
     xlab = "", 
     ylab = "", 
     ylim = range(c(d$y, d$z)), 
     pch = 19)

plt(col = "firebrick2",
    type = "lines",
    add = TRUE,
    c(1,1),
    c(1+1*2, 1-1*2),
    lwd = 2)

# points(1, 1, col = "firebrick2", bg = "white", pch = 21, cex = 1.3)

```
:::
:::

## Imputation - "Filling in the blank"

* Generate a new value to replace NAs
* Build a predictive model for variable with NAs from other variables

:::{.fragment}
* Many pitfalls:
  * replacing with the mean ❌ 
  * replacing with one value ❌
  * replacing with unrealistic values ❌
:::

## Uses for imputed values

*Are the imputed values the means or the ends?*

- Draw a pretty picture
  - Fill in points on a UMAP or image
- Downstream statistical inference
  - $P(\theta \mid Y_{mis})$

***Inference is much more demanding!***

## Negative effects of missing data

* Obvious: Missing data → less information → imprecise estimates
* Insidious: Patterns of missingness can *induce* bias if ignored

## Types of missingness

:::{.column width=60%}
* Missing...
  * "...completely at random" (MCAR)
  * "...at random" (MAR)
  * "...not at random" (MNAR)
* These terms are famously confusing.
* Draw a directed acyclic graph (DAG) instead.
:::

:::{.fragment}

* Example: Studying, homework, and dogs.

![](images/2025-05-06_15-58-00.png){fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);" .absolute left=1250 top=0}

:::{.absolute left=900 width=22% top=50}
<small> Arrows = causal relationships </small>

<small> Dotted = latent truth </small>

<small> Starred = observed with NAs </small>
:::

:::

# Strategies

## Examining missingness

* Count observations with any NAs
* Tabulate features that tend to go missing together
* Check if NAs are associated with other variables

## Just drop them

* Only valid for MCAR, otherwise you'll get bias.
* At the very least, discuss the possible consequences of this choice.

```{r}
#| eval: false

nrow(na.omit(dat)) / nrow(dat)

```

## Multiple imputation (MI)

* Key idea: 
  1. Randomly impute missing values
  1. Fit a model to the imputed dataset
  1. Repeat 1-2 many times
  1. Aggregate ("pool") results
  
* Key assumption: "ignorability"

![](images/ch01-miflow-1.png){.absolute top=100 left=750 fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);" width=55%}

:::{.aside}
[*Flexible Imputation of Missing Data*](https://stefvanbuuren.name/fimd/), Stef van Buuren, [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)
:::

## Imputation model

:::{.column width=65%}
* Predict NAs in a covariate given all other covariates 
* Most common: **Predictive mean matching** and/or **regression**, see `?mice::mice.impute.*`

:::{.incremental}
* Mean of the non-NAs ❌ ❌
* Model predictive mean ❌
* Model predictive mean + noise ✅
* Predict + noise + parameter uncertainty ✅✅
* Predictive mean matching ✅✅
* LASSO, random forests, neural nets, etc
:::

:::{.fragment}
* `mice` comes with sane defaults, but always check and think. 
:::

:::

<!-- TODO: FIMD figure 3.1 but with only one predictor for simplicity -->

## Pooling



## "Ignorability" assumption

* "Does the chance of a value going missing depend on the value itself or other information we don't have?"
* If so, assumption violated.
* standard MI practice generally won't work.

:::{.notes}
Defining this concept precisely is complicated, but the first bullet gives the main idea.
:::

<!-- :::{.fragment} -->
<!-- * If you have other data that can provide information on the underlying values, speak to a statistician and mention the phrase *"Bayesian imputation"*. -->
<!-- ::: -->

## Quiz 

```{r}
ex_dat[1:7,c(2:4,1)] |> print(row.names = FALSE)
```


[<span style="color:#666666; font-style: italic;"> <small> Missing values in survey data </small> </span>]{.absolute left=100 top=550}

![ ](images/dg_tmp.png){.absolute left=950 top=100 width=44%} 

[<span style="color:#666666; font-style: italic;"> <small> Missing values in imaging data </small> </span>]{.absolute left=950 top=550}

:::{.absolute top=600}
Think / discuss which of these are probably MCAR/MAR/NMAR and/or exhibit ignorable missingness.
:::

## Joint imputation

:::{.column width=65%}
* Use *informative auxiliary variables* to simultaneously:
  * impute NAs
  * infer missingness relationship 
* Generally requires:
  * informative auxiliary variables
  * bespoke modeling in a probabilistic programming language 
  * fairly large sample sizes
  * domain knowledge
:::

![](images/covid_dag.png){fig-alt="" .absolute left=1100 top=100 width=30%}

# Examples

## Highly accurate imputation - Genotype from markers

:::{.column width=60%}
* Input: microarray genotypes of ~100k-5M common marker SNPs
* Output: genotypes at query SNPs
* Output uncertainty: surprisingly low for common variants
* SHAPEIT - Segmented HAPlotype Estimation and Imputation Tools
:::

:::{.column width=40% .absolute top=100 left=1000}
![](images/2025-08-04_13-25-08.png){fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);"}
![](images/2025-08-04_13-22-07.png){fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);"}
:::

<!-- TODO: picture of a microarray -->

## Rough imputation for pictures - single-cell proteomics

:::{.column width=60%}
* Proof of concept. N = 8.
* Elastic Net, XGBoost, AutoEncoders to impute 16 protein levels of single cells.
* MAE b/w 0.05-0.15 on a 0-1 scale.
* Imputed error fairly high → Lessened downstream utility
* Batch, instrument effects? Unclear.
:::

:::{.column width=40%}
![](images/2025-08-04_12-36-50.png){fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);"}
![](images/2025-08-04_12-38-36.png){fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);"}
:::

## COVID incidence 

> "... a model that allows for simultaneous modeling of the disease and missingness processes, and that incorporates information on spatial clustering of risk"

> "population relative risk estimates by race during the early part of the COVID-19 pandemic in Michigan were understated for non-white residents, compared to white residents, when cases missing race were dropped or had these values imputed using MI."

![](images/2025-07-01_13-17-22.png){fig-alt="" style="filter: drop-shadow(0 0 0.75rem grey);" width=35% fig-align="center"} 

:::{.aside}

*Modeling racial/ethnic differences in COVID-19 incidence with covariates subject to nonrandom missingness* - Trangucci 2023
:::

# End matter


## Ethics

> "The ethical statistical practitioner ... seeks to *understand and mitigate* known or *suspected* limitations, defects, or biases in the data ... and communicates potential impacts on the interpretation [or] conclusions...[and] Avoids compromising validity for expediency." ^[ [ASA Ethical Guidelines for Statistical Practice](https://www.amstat.org/your-career/ethical-guidelines-for-statistical-practice),  emphasis mine]

* Be honest. Ignoring impactful patterns is not honest!
* Do your due diligence. 
* Ask for help if you need it.

# On to the workshop!

ccb.connect.hms.harvard.edu/missing_data_workshop/

# Extra

## How to do missing data analysis in Python

## ~~How to do missing data analysis in Python~~

<span style="font-size: 140%;"> **Don't do missing data analysis in Python. ** </span> 

:::{.incremental}
* MI ecosystem all but non-existent in Python.
* `scikit-learn` encourages single imputation ❌
  * statistical malpractice
* `scikit-learn` is for machine learning, *not* probabilistic inference 
  * See also the infamous `sklearn.linear_model.LogisticRegression`
* [`miceforest`](https://miceforest.readthedocs.io/en/latest/) - possibly okay for small data if computational burden of RFs is acceptable
:::

## Examples

* genotype impute
* scdropout
* COVID data
* find a good survey example



